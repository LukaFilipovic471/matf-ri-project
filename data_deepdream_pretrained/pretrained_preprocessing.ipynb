{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efc0bcef-89d2-427d-b69b-158882f7712b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c464ed77-307f-4ce4-bcf9-aa39ae0a2cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepDream(nn.Module):\n",
    "    def __init__(self, model, layer_idx):\n",
    "        super(DeepDream, self).__init__()\n",
    "        self.features = self.get_required_layers(model, layer_idx)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "\n",
    "    def get_required_layers(self, model, layer_idx):\n",
    "        if isinstance(model, nn.Sequential):\n",
    "            return nn.Sequential(*list(model.children())[:layer_idx+1])\n",
    "        elif isinstance(model, nn.Module):\n",
    "            return model  # You might need to adjust this depending on the structure of your model\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported model type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82d80784-1062-4c3e-ba1b-67718de87004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_dream(image_tensor, model, layer_idx, iterations, lr, octave_scale, output_path):\n",
    "    # Convert image tensor to nn.Parameter\n",
    "    img = nn.Parameter(image_tensor.to(device))\n",
    "\n",
    "    # Define the deep dream model\n",
    "    dream_model = DeepDream(model, layer_idx).to(device)\n",
    "    \n",
    "    # Define the optimizer\n",
    "    optimizer = optim.Adam([img], lr=lr)\n",
    "    \n",
    "    # DeepDream iterations\n",
    "    for i in range(iterations):\n",
    "        optimizer.zero_grad()\n",
    "        features = dream_model(img)\n",
    "        loss = features.norm()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        # Apply the octave scaling\n",
    "        img.data = img.data + octave_scale * img.grad.data\n",
    "    \n",
    "        # Zero the gradient\n",
    "        img.grad.data.zero_()\n",
    "    \n",
    "        # Clip the image values to be in the valid range\n",
    "        img.data = torch.clamp(img.data, 0, 1)\n",
    "    \n",
    "    # Save the final deep dream image\n",
    "    result = transforms.ToPILImage()(img.squeeze(0).cpu())\n",
    "    result.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccf556d6-ee39-4ec9-98e6-bbdd3fb80d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Specify the layer index for deep dream (you can experiment with different layers)\n",
    "layer_index = 10\n",
    "\n",
    "iterations = 20\n",
    "learning_rate = 0.01\n",
    "octave_scale = 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cf18c06-f212-44a9-b5e3-2a278e2218dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/user/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.inception_v3(pretrained=True).eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50a57586-329e-4db2-b981-f8debf3c675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),  # Resize images to the same dimensions as expected by InceptionV3\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),  # Resize images to the same dimensions as expected by InceptionV3\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09dd074e-be6e-4d0e-b535-02f5b4b4acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(root='../data/train', transform=train_transform)\n",
    "test_dataset = datasets.ImageFolder(root='../data/validation', transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5688bd6-635c-4475-b528-3d0cf5388758",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2000):\n",
    "    img, label = train_dataset[i]\n",
    "    output_image_path = f'deepdream_pt_train_pic{i}.jpg'\n",
    "    deep_dream(img.reshape(1, img.shape[0], img.shape[1], img.shape[2]), model, layer_index, iterations, learning_rate, octave_scale, output_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63619924-92c5-4d66-9dd1-28d047036600",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    img, label = test_dataset[i]\n",
    "    output_image_path = f'deepdream2_pt_test_pic{i}.jpg'\n",
    "    deep_dream(img.reshape(1, img.shape[0], img.shape[1], img.shape[2]), model, layer_index, iterations, learning_rate, octave_scale, output_image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
